{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d64a83e",
   "metadata": {},
   "source": [
    "This file goes over all other code that we had in our train files.\n",
    "I removed them from other files and put them here because they are useful for understanding the structure of this assignment, but not useful to train or test a model. \n",
    "These cells can be taken and added to certain places in files like train_small_snn.ipynb if needed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edc6de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the datasets. This dataset is huge (~17gb), so no need to do this more than once. \n",
    "# If you are opening this on a google colab, there should be a data pipeline between the colab and a google drive location with the data, so no need to install data locally. \n",
    "# tonic.datasets.DVSGesture(save_to=\"/home/gauravgupta/CMPM118/data\", train=True)\n",
    "# tonic.datasets.DVSGesture(save_to=\"/home/gauravgupta/CMPM118/data\", train=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5898e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # each sequence of gestures for each subject is divided into 11 .npy files, which are named according to the target labels. \n",
    "# # file_name = '/kaggle/input/create-dvs128gesture-tonic-dataset/DVSGesture/ibmGestureTest/user26_led/9.npy'\n",
    "# file_name = '/home/gauravgupta/CMPM118/data/DVSGesture/ibmGestureTest/user26_led/9.npy'\n",
    "\n",
    "# # each file contains a list of events (x-pos, y-pos, polarity, timestamp).\n",
    "# arr = np.load(file_name)\n",
    "# arr[:, 3] *= 1000  # convert from ms to us\n",
    "# dtype = np.dtype([(\"x\", np.int16), (\"y\", np.int16), (\"p\", bool), (\"t\", np.int64)])\n",
    "# arr = rf.unstructured_to_structured(arr, dtype)\n",
    "\n",
    "# print(\"A single event:\", arr[0], \"as (x-pos, y-pos, polarity, timestamp).\")\n",
    "\n",
    "# # np.savetxt(\"./DVSGesture/ibmGestureTest/user26_led/9.csv\", arr, delimiter=\",\") # save as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebcf800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tonic\n",
    "# import matplotlib.pyplot as plt\n",
    "# from IPython.display import HTML\n",
    "\n",
    "# def to_frames(events):\n",
    "#      # creates dense frames from events by binning them in different ways\n",
    "#     frame_transform = tonic.transforms.ToFrame(\n",
    "#         sensor_size=tonic.datasets.DVSGesture.sensor_size, \n",
    "#         #time_window=10000)\n",
    "#         n_time_bins=100)\n",
    "#         #event_count=1000)\n",
    "#     return frame_transform(events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0883ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calculateLZC(events):\n",
    "#     spike_seq = (events['p'] > 0).astype(int).flatten()  # 1 if spike, 0 if inactive\n",
    "#     spike_seq_string = ''.join(map(str, spike_seq.tolist()))\n",
    "#     lz_score = lempel_ziv_complexity(spike_seq_string)\n",
    "#     print(f\"LZ complexity: \", lz_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7201290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculate lempel ziv complexity for a single piece of data\n",
    "# # \n",
    "# #  Load in the data. When we do train[1], we are getting one \"video\" of data. \n",
    "# dataset_path = '/home/gauravgupta/CMPM118/data'\n",
    "# train = tonic.datasets.DVSGesture(save_to=dataset_path, train=True)\n",
    "# test = tonic.datasets.DVSGesture(save_to=dataset_path, train=False)\n",
    "# events, label = train[8]\n",
    "\n",
    "# calculateLZC(events)\n",
    "\n",
    "\n",
    "# # Flatten temporal frames into binary spike stream\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611dcaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_path = '/home/gauravgupta/CMPM118/data'\n",
    "# train = tonic.datasets.DVSGesture(save_to=dataset_path, train=True)\n",
    "# test = tonic.datasets.DVSGesture(save_to=dataset_path, train=False)\n",
    "\n",
    "# events, label = train[6]\n",
    "# frames = to_frames(events)\n",
    "\n",
    "# print(\"Train dataset contains\", len(train), \"samples.\")\n",
    "# print(\"There are\", len(events), \"events in the selected sample.\")\n",
    "# print(\"A single event:\", events[1], \"as (x-pos, y-pos, polarity, timestamp).\")\n",
    "# print (frames.shape, label)\n",
    "\n",
    "# ani = tonic.utils.plot_animation(frames) # plot one frame\n",
    "# HTML(ani.to_jshtml()) # animate all frames\n",
    "\n",
    "# lzc = \"\"\n",
    "# lzc_list = []\n",
    "\n",
    "# binary_frames = (frames > 0).astype(int)\n",
    "# flat_frames = binary_frames.reshape(binary_frames.shape[0], -1)\n",
    "# for frame in flat_frames:\n",
    "#     lzc = \"\".join(map(str, frame))\n",
    "#     lzc_list.append(lempel_ziv_complexity(lzc))\n",
    "\n",
    "# fig, axes = plt.subplots(1, 1, figsize=(18,4))\n",
    "# axes.plot(lzc_list)\n",
    "# axes.set_title(\"LZC Over Time\")\n",
    "# axes.set_xlabel(\"Frame\")\n",
    "# axes.set_ylabel(\"LZC\")\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406a8dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_path = '/home/gauravgupta/CMPM118/data'\n",
    "# w,h=64,64\n",
    "# n_frames=100\n",
    "# debug = False\n",
    "\n",
    "# transforms = tonic.transforms.Compose([\n",
    "#     tonic.transforms.Denoise(filter_time=10000), # removes outlier events with inactive surrounding pixels for 10ms\n",
    "#     tonic.transforms.Downsample(sensor_size=tonic.datasets.DVSGesture.sensor_size, target_size=(w,h)), # downsampling image\n",
    "#     tonic.transforms.ToFrame(sensor_size=(w,h,2), n_time_bins=n_frames), # n_frames frames per trail\n",
    "# ])\n",
    "\n",
    "# train2 = tonic.datasets.DVSGesture(save_to=dataset_path, transform=transforms, train=True)\n",
    "# test2 = tonic.datasets.DVSGesture(save_to=dataset_path, transform=transforms, train=False)\n",
    "\n",
    "# cache_root = f\"/home/gauravgupta/CMPM118/data/dvsgesture/{w}x{h}_T{n_frames}\"\n",
    "# cached_train = tonic.DiskCachedDataset(train2, cache_path=f\"{cache_root}/train\")\n",
    "# cached_test  = tonic.DiskCachedDataset(test2,  cache_path=f\"{cache_root}/test\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # to visualize the LZC and video of one video, uncomment the code below. This is NOT NECESSARY for training.  \n",
    "\n",
    "\n",
    "\n",
    "# # frames, label = cached_train[1]\n",
    "# # ani = tonic.utils.plot_animation(frames)\n",
    "# # print(frames.shape, label)\n",
    "# # HTML(ani.to_jshtml())\n",
    "\n",
    "# # lzc = \"\"\n",
    "# # lzc_list = []\n",
    "\n",
    "# # binary_frames = (frames > 0).astype(int)\n",
    "# # flat_frames = binary_frames.reshape(binary_frames.shape[0], -1)\n",
    "# # for frame in flat_frames:\n",
    "# #     lzc = \"\".join(map(str, frame))\n",
    "# #     lzc_list.append(lempel_ziv_complexity(lzc))\n",
    "\n",
    "# # fig, axes = plt.subplots(1, 1, figsize=(18,4))\n",
    "# # axes.plot(lzc_list)\n",
    "# # axes.set_title(\"LZC Over Time\")\n",
    "# # axes.set_xlabel(\"Frame\")\n",
    "# # axes.set_ylabel(\"LZC\")\n",
    "\n",
    "# # plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
