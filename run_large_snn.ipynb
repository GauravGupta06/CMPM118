{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "102900a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# all required libraries below\n",
    "%pip install numpy --quiet\n",
    "%pip install tonic --quiet\n",
    "%pip install matplotlib --quiet\n",
    "%pip install snntorch --quiet\n",
    "%pip install torch --quiet\n",
    "%pip install Lempel-Ziv-Complexity --quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08d6c7ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gauravgupta/CMPM118/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# All imports go here\n",
    "import numpy as np\n",
    "import numpy.lib.recfunctions as rf\n",
    "import tonic\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import HTML\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import snntorch as snn\n",
    "from snntorch import surrogate\n",
    "from snntorch import functional as SF\n",
    "from snntorch import utils\n",
    "from lempel_ziv_complexity import lempel_ziv_complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2aed32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "866d908a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateLZC(events):\n",
    "    spike_seq = (events['p'] > 0).astype(int).flatten()  # 1 if spike, 0 if inactive\n",
    "    spike_seq_string = ''.join(map(str, spike_seq.tolist()))\n",
    "    lz_score = lempel_ziv_complexity(spike_seq_string)\n",
    "    print(f\"LZ complexity: \", lz_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "219f46eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example on how to calculate lempel ziv complexity for a single piece of data\n",
    "# # \n",
    "# #  Load in the data. When we do train[1], we are getting one \"video\" of data. \n",
    "# dataset_path = '/home/gauravgupta/CMPM118/data'\n",
    "# train = tonic.datasets.DVSGesture(save_to=dataset_path, train=True)\n",
    "# test = tonic.datasets.DVSGesture(save_to=dataset_path, train=False)\n",
    "# events, label = train[8]\n",
    "\n",
    "# calculateLZC(events)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c35156fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "w,h=32,32\n",
    "n_frames=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fcaf9f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape before flatten: torch.Size([1, 32, 5, 5])\n",
      "Flattened size: 800\n"
     ]
    }
   ],
   "source": [
    "# This is used to figure out how many fully connected neurons need to be present in the last layer. This number depends on the w and h values. \n",
    "\n",
    "test_input = torch.zeros((1, 2, w, h))  # 2 polarity channels\n",
    "x = nn.Conv2d(2, 12, 5)(test_input)\n",
    "x = nn.MaxPool2d(2)(x)\n",
    "x = nn.Conv2d(12, 32, 5)(x)\n",
    "x = nn.MaxPool2d(2)(x)\n",
    "print(\"Output shape before flatten:\", x.shape)\n",
    "print(\"Flattened size:\", x.numel())\n",
    "flattenedSize = x.numel()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31635f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "grad = snn.surrogate.fast_sigmoid(slope=25)\n",
    "beta = 0.5\n",
    "\n",
    "net = nn.Sequential(\n",
    "    nn.Conv2d(2, 12, 5),\n",
    "    nn.MaxPool2d(2),\n",
    "    snn.Leaky(beta=beta, spike_grad=grad, init_hidden=True),\n",
    "    nn.Conv2d(12, 32, 5),\n",
    "    nn.MaxPool2d(2),\n",
    "    snn.Leaky(beta=beta, spike_grad=grad, init_hidden=True),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(flattenedSize, 11),   # make sure 800 matches flattenedSize\n",
    "    snn.Leaky(beta=beta, spike_grad=grad, init_hidden=True, output=True)\n",
    ").to(device)\n",
    "\n",
    "model_path = \"results/small/models/Sparse_Take44_32x32_T32.pth\"\n",
    "net.load_state_dict(torch.load(model_path, map_location=device))\n",
    "net.eval()\n",
    "print(\"Model loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0143421a",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "cache_root = f\"data/dvsgesture/{w}x{h}_T{n_frames}\"\n",
    "\n",
    "cached_test = tonic.DiskCachedDataset(None, cache_path=f\"{cache_root}/test\")\n",
    "\n",
    "\n",
    "# cached_test = tonic.DiskCachedDataset(\n",
    "#     tonic.datasets.DVSGesture(save_to=dataset_path, train=False),\n",
    "#     cache_path=f\"{cache_root}/test\"\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "# frames, label = cached_test[1]\n",
    "# ani = tonic.utils.plot_animation(frames)\n",
    "# print(frames.shape, label)\n",
    "# HTML(ani.to_jshtml())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# to visualize the LZC and video of one video, uncomment the code below. This is NOT NECESSARY for training OR running.  \n",
    "\n",
    "\n",
    "\n",
    "# frames, label = cached_train[1]\n",
    "# ani = tonic.utils.plot_animation(frames)\n",
    "# print(frames.shape, label)\n",
    "# HTML(ani.to_jshtml())\n",
    "\n",
    "# lzc = \"\"\n",
    "# lzc_list = []\n",
    "\n",
    "# binary_frames = (frames > 0).astype(int)\n",
    "# flat_frames = binary_frames.reshape(binary_frames.shape[0], -1)\n",
    "# for frame in flat_frames:\n",
    "#     lzc = \"\".join(map(str, frame))\n",
    "#     lzc_list.append(lempel_ziv_complexity(lzc))\n",
    "\n",
    "# fig, axes = plt.subplots(1, 1, figsize=(18,4))\n",
    "# axes.plot(lzc_list)\n",
    "# axes.set_title(\"LZC Over Time\")\n",
    "# axes.set_xlabel(\"Frame\")\n",
    "# axes.set_ylabel(\"LZC\")\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "851d016a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(net, data):\n",
    "    spk_rec = []\n",
    "    snn.utils.reset(net)\n",
    "    with torch.no_grad():\n",
    "        for t in range(data.size(0)):          # data: [T, 2, H, W]\n",
    "            x = data[t].unsqueeze(0).to(device) # -> [1, 2, H, W]\n",
    "            spk_out, _ = net(x)\n",
    "            spk_rec.append(spk_out)             # [1, 11]\n",
    "    return torch.stack(spk_rec)  \n",
    "\n",
    "\n",
    "def predict_sample(frames):\n",
    "    frames = torch.tensor(frames, dtype=torch.float)  # [T, 2, H, W]\n",
    "    spk_rec = forward_pass(net, frames)\n",
    "    counts = spk_rec.sum(0)            # [1, 11]\n",
    "    return counts.argmax(1).item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1146da68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True label: 0, Predicted label: 0\n",
      "195\n",
      "262\n",
      "0.7442748091603053\n"
     ]
    }
   ],
   "source": [
    "frames, label = cached_test[1]\n",
    "\n",
    "# this prints out one prediction\n",
    "pred = predict_sample(frames)\n",
    "print(f\"True label: {label}, Predicted label: {pred}\")\n",
    "\n",
    "num = 0\n",
    "total = 0\n",
    "for i in range (262):\n",
    "    total += 1\n",
    "    frames, lable = cached_test[i]\n",
    "    pred = predict_sample(frames)\n",
    "    if (lable == pred):\n",
    "        num += 1\n",
    "\n",
    "\n",
    "print(num)\n",
    "print(total)\n",
    "print(num/total)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
