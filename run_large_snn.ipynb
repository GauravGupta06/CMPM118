{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "102900a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# all required libraries below\n",
    "%pip install numpy --quiet\n",
    "%pip install tonic --quiet\n",
    "%pip install matplotlib --quiet\n",
    "%pip install snntorch --quiet\n",
    "%pip install torch --quiet\n",
    "%pip install Lempel-Ziv-Complexity --quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08d6c7ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gauravgupta/CMPM118/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# All imports go here\n",
    "import numpy as np\n",
    "import numpy.lib.recfunctions as rf\n",
    "import tonic\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import HTML\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import snntorch as snn\n",
    "from snntorch import surrogate\n",
    "from snntorch import functional as SF\n",
    "from snntorch import utils\n",
    "from lempel_ziv_complexity import lempel_ziv_complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2aed32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "866d908a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateLZC(events):\n",
    "    spike_seq = (events['p'] > 0).astype(int).flatten()  # 1 if spike, 0 if inactive\n",
    "    spike_seq_string = ''.join(map(str, spike_seq.tolist()))\n",
    "    lz_score = lempel_ziv_complexity(spike_seq_string)\n",
    "    print(f\"LZ complexity: \", lz_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "219f46eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example on how to calculate lempel ziv complexity for a single piece of data\n",
    "# # \n",
    "# #  Load in the data. When we do train[1], we are getting one \"video\" of data. \n",
    "# dataset_path = '/home/gauravgupta/CMPM118/data'\n",
    "# train = tonic.datasets.DVSGesture(save_to=dataset_path, train=True)\n",
    "# test = tonic.datasets.DVSGesture(save_to=dataset_path, train=False)\n",
    "# events, label = train[8]\n",
    "\n",
    "# calculateLZC(events)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c35156fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "w,h=64,64\n",
    "n_frames=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fcaf9f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape before flatten: torch.Size([1, 32, 13, 13])\n",
      "Flattened size: 5408\n"
     ]
    }
   ],
   "source": [
    "# This is used to figure out how many fully connected neurons need to be present in the last layer. This number depends on the w and h values. \n",
    "\n",
    "test_input = torch.zeros((1, 2, w, h))  # 2 polarity channels\n",
    "x = nn.Conv2d(2, 12, 5)(test_input)\n",
    "x = nn.MaxPool2d(2)(x)\n",
    "x = nn.Conv2d(12, 32, 5)(x)\n",
    "x = nn.MaxPool2d(2)(x)\n",
    "print(\"Output shape before flatten:\", x.shape)\n",
    "print(\"Flattened size:\", x.numel())\n",
    "flattenedSize = x.numel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31635f3d",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Sequential:\n\tsize mismatch for 7.weight: copying a param with shape torch.Size([11, 5408]) from checkpoint, the shape in current model is torch.Size([11, 800]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 17\u001b[0m\n\u001b[1;32m      4\u001b[0m net \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSequential(\n\u001b[1;32m      5\u001b[0m     nn\u001b[38;5;241m.\u001b[39mConv2d(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m5\u001b[39m),\n\u001b[1;32m      6\u001b[0m     nn\u001b[38;5;241m.\u001b[39mMaxPool2d(\u001b[38;5;241m2\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m     snn\u001b[38;5;241m.\u001b[39mLeaky(beta\u001b[38;5;241m=\u001b[39mbeta, spike_grad\u001b[38;5;241m=\u001b[39mgrad, init_hidden\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     14\u001b[0m )\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     16\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults/large/models/Large_Take4.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 17\u001b[0m \u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m net\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel loaded successfully.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/CMPM118/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:2624\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2616\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2617\u001b[0m             \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   2618\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2619\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[1;32m   2620\u001b[0m             ),\n\u001b[1;32m   2621\u001b[0m         )\n\u001b[1;32m   2623\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2624\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   2625\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2626\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)\n\u001b[1;32m   2627\u001b[0m         )\n\u001b[1;32m   2628\u001b[0m     )\n\u001b[1;32m   2629\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Sequential:\n\tsize mismatch for 7.weight: copying a param with shape torch.Size([11, 5408]) from checkpoint, the shape in current model is torch.Size([11, 800])."
     ]
    }
   ],
   "source": [
    "grad = snn.surrogate.fast_sigmoid(slope=25)\n",
    "beta = 0.5\n",
    "\n",
    "net = nn.Sequential(\n",
    "    nn.Conv2d(2, 12, 5),\n",
    "    nn.MaxPool2d(2),\n",
    "    snn.Leaky(beta=beta, spike_grad=grad, init_hidden=True),\n",
    "    nn.Conv2d(12, 32, 5),\n",
    "    nn.MaxPool2d(2),\n",
    "    snn.Leaky(beta=beta, spike_grad=grad, init_hidden=True),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(flattenedSize, 11),   # make sure 800 matches flattenedSize\n",
    "    snn.Leaky(beta=beta, spike_grad=grad, init_hidden=True, output=True)\n",
    ").to(device)\n",
    "\n",
    "model_path = \"results/large/models/Large_Take4.pth\"\n",
    "net.load_state_dict(torch.load(model_path, map_location=device))\n",
    "net.eval()\n",
    "print(\"Model loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0143421a",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "cache_root = f\"data/dvsgesture/{w}x{h}_T{n_frames}\"\n",
    "\n",
    "cached_test = tonic.DiskCachedDataset(None, cache_path=f\"{cache_root}/test\")\n",
    "\n",
    "\n",
    "# cached_test = tonic.DiskCachedDataset(\n",
    "#     tonic.datasets.DVSGesture(save_to=dataset_path, train=False),\n",
    "#     cache_path=f\"{cache_root}/test\"\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "# frames, label = cached_test[1]\n",
    "# ani = tonic.utils.plot_animation(frames)\n",
    "# print(frames.shape, label)\n",
    "# HTML(ani.to_jshtml())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# to visualize the LZC and video of one video, uncomment the code below. This is NOT NECESSARY for training OR running.  \n",
    "\n",
    "\n",
    "\n",
    "# frames, label = cached_train[1]\n",
    "# ani = tonic.utils.plot_animation(frames)\n",
    "# print(frames.shape, label)\n",
    "# HTML(ani.to_jshtml())\n",
    "\n",
    "# lzc = \"\"\n",
    "# lzc_list = []\n",
    "\n",
    "# binary_frames = (frames > 0).astype(int)\n",
    "# flat_frames = binary_frames.reshape(binary_frames.shape[0], -1)\n",
    "# for frame in flat_frames:\n",
    "#     lzc = \"\".join(map(str, frame))\n",
    "#     lzc_list.append(lempel_ziv_complexity(lzc))\n",
    "\n",
    "# fig, axes = plt.subplots(1, 1, figsize=(18,4))\n",
    "# axes.plot(lzc_list)\n",
    "# axes.set_title(\"LZC Over Time\")\n",
    "# axes.set_xlabel(\"Frame\")\n",
    "# axes.set_ylabel(\"LZC\")\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851d016a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(net, data):\n",
    "    spk_rec = []\n",
    "    snn.utils.reset(net)\n",
    "    with torch.no_grad():\n",
    "        for t in range(data.size(0)):          # data: [T, 2, H, W]\n",
    "            x = data[t].unsqueeze(0).to(device) # -> [1, 2, H, W]\n",
    "            spk_out, _ = net(x)\n",
    "            spk_rec.append(spk_out)             # [1, 11]\n",
    "    return torch.stack(spk_rec)  \n",
    "\n",
    "\n",
    "def predict_sample(frames):\n",
    "    frames = torch.tensor(frames, dtype=torch.float)  # [T, 2, H, W]\n",
    "    spk_rec = forward_pass(net, frames)\n",
    "    counts = spk_rec.sum(0)            # [1, 11]\n",
    "    return counts.argmax(1).item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1146da68",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames, label = cached_test[1]\n",
    "\n",
    "# this prints out one prediction\n",
    "pred = predict_sample(frames)\n",
    "print(f\"True label: {label}, Predicted label: {pred}\")\n",
    "\n",
    "num = 0\n",
    "total = 0\n",
    "for i in range (262):\n",
    "    total += 1\n",
    "    frames, lable = cached_test[i]\n",
    "    pred = predict_sample(frames)\n",
    "    if (lable == pred):\n",
    "        num += 1\n",
    "\n",
    "\n",
    "print(num)\n",
    "print(total)\n",
    "print(num/total)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
