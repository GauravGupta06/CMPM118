{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371789c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all required libraries below\n",
    "%pip install numpy --quiet\n",
    "%pip install tonic --quiet\n",
    "%pip install matplotlib --quiet\n",
    "%pip install snntorch --quiet\n",
    "%pip install torch --quiet\n",
    "%pip install Lempel-Ziv-Complexity --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00eafdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tonic\n",
    "import torch\n",
    "import snntorch as snn\n",
    "import torch.nn as nn\n",
    "from lempel_ziv_complexity import lempel_ziv_complexity\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb163b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# larger model net\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(device) \n",
    "\n",
    "w = 64\n",
    "h = 64\n",
    "n_frames = 100\n",
    "\n",
    "cache_root_dense = f\"data/dvsgesture/{w}x{h}_T{n_frames}\"\n",
    "cached_test_dense= tonic.DiskCachedDataset(None, cache_path=f\"{cache_root_dense}/test\")\n",
    "\n",
    "test_input = torch.zeros((1, 2, w, h))  # 2 polarity channels\n",
    "x = nn.Conv2d(2, 8, 3)(test_input)\n",
    "x = nn.MaxPool2d(2)(x)\n",
    "print(\"Output shape before flatten:\", x.shape)\n",
    "print(\"Flattened size:\", x.numel())\n",
    "flattenedSize = x.numel() \n",
    "\n",
    "grad = snn.surrogate.fast_sigmoid(slope=25)\n",
    "beta = 0.5\n",
    "\n",
    "dense_model = nn.Sequential(\n",
    "    nn.Conv2d(2, 12, 5),\n",
    "    nn.MaxPool2d(2),\n",
    "    snn.Leaky(beta=beta, spike_grad=grad, init_hidden=True),\n",
    "    nn.Conv2d(12, 32, 5),\n",
    "    nn.MaxPool2d(2),\n",
    "    snn.Leaky(beta=beta, spike_grad=grad, init_hidden=True),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(flattenedSize, 11),   # make sure 800 matches flattenedSize\n",
    "    snn.Leaky(beta=beta, spike_grad=grad, init_hidden=True, output=True)\n",
    ").to(device)\n",
    "\n",
    "model_path = \"results/large/models/Large_Take2.pth\"\n",
    "dense_model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "dense_model.eval()\n",
    "print(\"Model loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45f3033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# small model net\n",
    "w = 32\n",
    "h = 32\n",
    "n_frames = 5\n",
    "\n",
    "cache_root_sparse = f\"data/dvsgesture/{w}x{h}_T{n_frames}\"\n",
    "cached_test_sparse = tonic.DiskCachedDataset(None, cache_path=f\"{cache_root_sparse}/test\")\n",
    "\n",
    "test_input = torch.zeros((1, 2, w, h))  # 2 polarity channels\n",
    "x = nn.Conv2d(2, 8, 3)(test_input)\n",
    "x = nn.MaxPool2d(2)(x)\n",
    "print(\"Output shape before flatten:\", x.shape)\n",
    "print(\"Flattened size:\", x.numel())\n",
    "flattenedSize = x.numel()\n",
    "\n",
    "grad = snn.surrogate.fast_sigmoid(slope=25)\n",
    "beta = 0.5\n",
    "\n",
    "sparse_model = nn.Sequential(\n",
    "    nn.Conv2d(2, 8, 3), # in_channels, out_channels, kernel_size\n",
    "    nn.MaxPool2d(2),\n",
    "    snn.Leaky(beta=beta, spike_grad=grad, init_hidden=True),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(flattenedSize, 11),\n",
    "    snn.Leaky(beta=beta, spike_grad=grad, init_hidden=True, output=True)\n",
    ").to(device)\n",
    "\n",
    "model_path = \"results/small/models/Small_Take2_32x32_T5.pth\"\n",
    "sparse_model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "sparse_model.eval()\n",
    "print(\"Model loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e2fc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(net, data):\n",
    "    spk_rec = []\n",
    "    snn.utils.reset(net)\n",
    "    with torch.no_grad():\n",
    "        for t in range(data.size(0)):          # data: [T, 2, H, W]\n",
    "            x = data[t].unsqueeze(0).to(device) # -> [1, 2, H, W]\n",
    "            spk_out, _ = net(x)\n",
    "            spk_rec.append(spk_out)             # [1, 11]\n",
    "    return torch.stack(spk_rec)  \n",
    "\n",
    "\n",
    "def predict_sample(frames):\n",
    "    frames = torch.tensor(frames, dtype=torch.float)  # [T, 2, H, W]\n",
    "    spk_rec = forward_pass(net, frames)\n",
    "    counts = spk_rec.sum(0)            # [1, 11]\n",
    "    return counts.argmax(1).item()\n",
    "\n",
    "\n",
    "def compute_lzc_from_events(events):\n",
    "    spike_seq = (events['p'] > 0).astype(int).flatten()\n",
    "    spike_seq_string = ''.join(map(str, spike_seq.tolist()))\n",
    "    lz_score = lempel_ziv_complexity(spike_seq_string)\n",
    "    return lz_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56382f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models_on_dataset(dataset_sparse, dataset_dense, sparse_model, dense_model, bin_size=0.005):\n",
    "    results = []\n",
    "    for (events_sparse, label_sparse),(events_dense, label_dense) in zip(dataset_sparse, dataset_dense):\n",
    "        lz_value = lempel_ziv_complexity(events_dense)\n",
    "        sparse_pred = sparse_model.predict_sample(events_sparse)\n",
    "        dense_pred = dense_model.predict_sample(events_dense)\n",
    "        # Choose which model did better for this input\n",
    "        # Here you decide which model is actually more accurate!\n",
    "        # Example: assume ground truth label; set as complex IF dense_pred matches label and sparse_pred does NOT\n",
    "        # Adjust logic as best fits your data and what you mean by \"complex\"\n",
    "        # expected to have same label\n",
    "        if dense_pred == label_dense and sparse_pred != label_sparse:\n",
    "            true_complex = 1\n",
    "        else:\n",
    "            true_complex = 0\n",
    "        results.append({\n",
    "            'label': label_dense,\n",
    "            'lz_value': lz_value,\n",
    "            'sparse_pred': sparse_pred,\n",
    "            'dense_pred': dense_pred,\n",
    "            'true_complex': true_complex\n",
    "        })\n",
    "    return results\n",
    "\n",
    "# 3. Threshold sweep, ROC-AUC curve, and optimal LZC threshold\n",
    "def threshold_sweep_and_roc(results):\n",
    "    # Ground truth: 1 if dense model was needed, 0 if sparse sufficed\n",
    "    y_true = np.array([r['true_complex'] for r in results])\n",
    "    lz_scores = np.array([r['lz_value'] for r in results])\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, lz_scores)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    gmean = np.sqrt(tpr * (1 - fpr))\n",
    "    idx = np.argmax(gmean)\n",
    "    optimal_threshold = thresholds[idx]\n",
    "    print(f\"Optimal LZC threshold: {optimal_threshold:.4f} (G-mean={gmean[idx]:.4f}) (AUC={roc_auc:.4f})\")\n",
    "    # Plot\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "    plt.scatter(fpr[idx], tpr[idx], color='red', label=f'Optimal G-mean\\n(Threshold={optimal_threshold:.4f})')\n",
    "    plt.plot([0,1],[0,1],'k--', label='Random')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve for LZC-based Routing')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return optimal_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e5f97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = evaluate_models_on_dataset(dataset, sparse_model, dense_model)\n",
    "optimal_threshold = threshold_sweep_and_roc(results)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
