{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "102900a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# all required libraries below\n",
    "%pip install numpy --quiet\n",
    "%pip install tonic --quiet\n",
    "%pip install matplotlib --quiet\n",
    "%pip install snntorch --quiet\n",
    "%pip install torch --quiet\n",
    "%pip install Lempel-Ziv-Complexity --quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08d6c7ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gauravgupta/CMPM118/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# All imports go here\n",
    "import numpy as np\n",
    "import numpy.lib.recfunctions as rf\n",
    "import tonic\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import HTML\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import snntorch as snn\n",
    "from snntorch import surrogate\n",
    "from snntorch import functional as SF\n",
    "from snntorch import utils\n",
    "from lempel_ziv_complexity import lempel_ziv_complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2aed32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de5a01da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the datasets. This dataset is huge (~17gb), so no need to do this more than once. \n",
    "# If you are opening this on a google colab, there should be a data pipeline between the colab and a google drive location with the data, so no need to install data locally. \n",
    "# tonic.datasets.DVSGesture(save_to=\"/home/gauravgupta/CMPM118/data\", train=True)\n",
    "# tonic.datasets.DVSGesture(save_to=\"/home/gauravgupta/CMPM118/data\", train=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fa5eca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # each sequence of gestures for each subject is divided into 11 .npy files, which are named according to the target labels. \n",
    "# # file_name = '/kaggle/input/create-dvs128gesture-tonic-dataset/DVSGesture/ibmGestureTest/user26_led/9.npy'\n",
    "# file_name = '/home/gauravgupta/CMPM118/data/DVSGesture/ibmGestureTest/user26_led/9.npy'\n",
    "\n",
    "# # each file contains a list of events (x-pos, y-pos, polarity, timestamp).\n",
    "# arr = np.load(file_name)\n",
    "# arr[:, 3] *= 1000  # convert from ms to us\n",
    "# dtype = np.dtype([(\"x\", np.int16), (\"y\", np.int16), (\"p\", bool), (\"t\", np.int64)])\n",
    "# arr = rf.unstructured_to_structured(arr, dtype)\n",
    "\n",
    "# print(\"A single event:\", arr[0], \"as (x-pos, y-pos, polarity, timestamp).\")\n",
    "\n",
    "# # np.savetxt(\"./DVSGesture/ibmGestureTest/user26_led/9.csv\", arr, delimiter=\",\") # save as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5c8d848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tonic\n",
    "# import matplotlib.pyplot as plt\n",
    "# from IPython.display import HTML\n",
    "\n",
    "# def to_frames(events):\n",
    "#      # creates dense frames from events by binning them in different ways\n",
    "#     frame_transform = tonic.transforms.ToFrame(\n",
    "#         sensor_size=tonic.datasets.DVSGesture.sensor_size, \n",
    "#         #time_window=10000)\n",
    "#         n_time_bins=100)\n",
    "#         #event_count=1000)\n",
    "#     return frame_transform(events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "866d908a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calculateLZC(events):\n",
    "#     spike_seq = (events['p'] > 0).astype(int).flatten()  # 1 if spike, 0 if inactive\n",
    "#     spike_seq_string = ''.join(map(str, spike_seq.tolist()))\n",
    "#     lz_score = lempel_ziv_complexity(spike_seq_string)\n",
    "#     print(f\"LZ complexity: \", lz_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "219f46eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculate lempel ziv complexity for a single piece of data\n",
    "# # \n",
    "# #  Load in the data. When we do train[1], we are getting one \"video\" of data. \n",
    "# dataset_path = '/home/gauravgupta/CMPM118/data'\n",
    "# train = tonic.datasets.DVSGesture(save_to=dataset_path, train=True)\n",
    "# test = tonic.datasets.DVSGesture(save_to=dataset_path, train=False)\n",
    "# events, label = train[8]\n",
    "\n",
    "# calculateLZC(events)\n",
    "\n",
    "\n",
    "# # Flatten temporal frames into binary spike stream\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22f8b3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '/home/gauravgupta/CMPM118/data'\n",
    "# train = tonic.datasets.DVSGesture(save_to=dataset_path, train=True)\n",
    "# test = tonic.datasets.DVSGesture(save_to=dataset_path, train=False)\n",
    "\n",
    "# events, label = train[6]\n",
    "# frames = to_frames(events)\n",
    "\n",
    "# print(\"Train dataset contains\", len(train), \"samples.\")\n",
    "# print(\"There are\", len(events), \"events in the selected sample.\")\n",
    "# print(\"A single event:\", events[1], \"as (x-pos, y-pos, polarity, timestamp).\")\n",
    "# print (frames.shape, label)\n",
    "\n",
    "# ani = tonic.utils.plot_animation(frames) # plot one frame\n",
    "# HTML(ani.to_jshtml()) # animate all frames\n",
    "\n",
    "# lzc = \"\"\n",
    "# lzc_list = []\n",
    "\n",
    "# binary_frames = (frames > 0).astype(int)\n",
    "# flat_frames = binary_frames.reshape(binary_frames.shape[0], -1)\n",
    "# for frame in flat_frames:\n",
    "#     lzc = \"\".join(map(str, frame))\n",
    "#     lzc_list.append(lempel_ziv_complexity(lzc))\n",
    "\n",
    "# fig, axes = plt.subplots(1, 1, figsize=(18,4))\n",
    "# axes.plot(lzc_list)\n",
    "# axes.set_title(\"LZC Over Time\")\n",
    "# axes.set_xlabel(\"Frame\")\n",
    "# axes.set_ylabel(\"LZC\")\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ded11e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "w,h=64,64\n",
    "n_frames=100\n",
    "debug = False\n",
    "\n",
    "transforms = tonic.transforms.Compose([\n",
    "    tonic.transforms.Denoise(filter_time=10000), # removes outlier events with inactive surrounding pixels for 10ms\n",
    "    tonic.transforms.Downsample(sensor_size=tonic.datasets.DVSGesture.sensor_size, target_size=(w,h)), # downsampling image\n",
    "    tonic.transforms.ToFrame(sensor_size=(w,h,2), n_time_bins=n_frames), # n_frames frames per trail\n",
    "])\n",
    "\n",
    "train2 = tonic.datasets.DVSGesture(save_to=dataset_path, transform=transforms, train=True)\n",
    "test2 = tonic.datasets.DVSGesture(save_to=dataset_path, transform=transforms, train=False)\n",
    "\n",
    "cache_root = f\"/home/gauravgupta/CMPM118/data/dvsgesture/{w}x{h}_T{n_frames}\"\n",
    "cached_train = tonic.DiskCachedDataset(train2, cache_path=f\"{cache_root}/train\")\n",
    "cached_test  = tonic.DiskCachedDataset(test2,  cache_path=f\"{cache_root}/test\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# to visualize the LZC and video of one video, uncomment the code below. This is NOT NECESSARY for training.  \n",
    "\n",
    "\n",
    "\n",
    "# frames, label = cached_train[1]\n",
    "# ani = tonic.utils.plot_animation(frames)\n",
    "# print(frames.shape, label)\n",
    "# HTML(ani.to_jshtml())\n",
    "\n",
    "# lzc = \"\"\n",
    "# lzc_list = []\n",
    "\n",
    "# binary_frames = (frames > 0).astype(int)\n",
    "# flat_frames = binary_frames.reshape(binary_frames.shape[0], -1)\n",
    "# for frame in flat_frames:\n",
    "#     lzc = \"\".join(map(str, frame))\n",
    "#     lzc_list.append(lempel_ziv_complexity(lzc))\n",
    "\n",
    "# fig, axes = plt.subplots(1, 1, figsize=(18,4))\n",
    "# axes.plot(lzc_list)\n",
    "# axes.set_title(\"LZC Over Time\")\n",
    "# axes.set_xlabel(\"Frame\")\n",
    "# axes.set_ylabel(\"LZC\")\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0fcaf9f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape before flatten: torch.Size([1, 32, 29, 29])\n",
      "Flattened size: 26912\n"
     ]
    }
   ],
   "source": [
    "# This is used to figure out how many fully connected neurons need to be present in the last layer. This number depends on the w and h values. \n",
    "\n",
    "test_input = torch.zeros((1, 2, w, h))  # 2 polarity channels\n",
    "x = nn.Conv2d(2, 12, 5)(test_input)\n",
    "x = nn.MaxPool2d(2)(x)\n",
    "x = nn.Conv2d(12, 32, 5)(x)\n",
    "x = nn.MaxPool2d(2)(x)\n",
    "print(\"Output shape before flatten:\", x.shape)\n",
    "print(\"Flattened size:\", x.numel())\n",
    "flattenedSize = x.numel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31635f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad = snn.surrogate.fast_sigmoid(slope=25) # surrogate.atan()\n",
    "beta = 0.5\n",
    "\n",
    "# 12C5-MP2-32C5-MP2-800FC11 https://snntorch.readthedocs.io/en/latest/tutorials/tutorial_7.html\n",
    "net = nn.Sequential(\n",
    "    nn.Conv2d(2, 12, 5), # in_channels, out_channels, kernel_size\n",
    "    nn.MaxPool2d(2),\n",
    "    snn.Leaky(beta=beta, spike_grad=grad, init_hidden=True),\n",
    "    nn.Conv2d(12, 32, 5),\n",
    "    nn.MaxPool2d(2),\n",
    "    snn.Leaky(beta=beta, spike_grad=grad, init_hidden=True),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(flattenedSize, 11),\n",
    "    snn.Leaky(beta=beta, spike_grad=grad, init_hidden=True, output=True)\n",
    ").to(device)\n",
    "\n",
    "def forward_pass(net, data):\n",
    "    spk_rec = []\n",
    "    snn.utils.reset(net)  # resets hidden states for all LIF neurons in net\n",
    "    for step in range(data.size(0)): # data.size(0) = number of time steps\n",
    "        spk_out, mem_out = net(data[step].to(device))\n",
    "        spk_rec.append(spk_out)\n",
    "    return torch.stack(spk_rec)\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.0001, betas=(0.9, 0.999))\n",
    "loss_fn = SF.mse_count_loss(correct_rate=0.8, incorrect_rate=0.2)\n",
    "\n",
    "loss_hist = []\n",
    "acc_hist = []\n",
    "test_acc_hist = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af65fd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model():\n",
    "    correct, total = 0, 0  \n",
    "    for batch, (data, targets) in enumerate(iter(test_loader)): \n",
    "        data, targets = data.to(device), targets.to(device) # [n_frames, batch, polarity, x-pos, y-pos] [batch] \n",
    "        spk_rec = forward_pass(net, data)         \n",
    "        correct += SF.accuracy_rate(spk_rec, targets) * data.shape[0]\n",
    "        total += data.shape[0]\n",
    "    return correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "064e12de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "128 128\n"
     ]
    }
   ],
   "source": [
    "# This cell is just for debugging. Not important\n",
    "print(n_frames)\n",
    "print(h, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851d016a",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 81150) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/CMPM118/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1285\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1284\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1285\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1286\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    112\u001b[0m timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m--> 113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Empty\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[0;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py:424\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_poll\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[0;32m--> 424\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    425\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py:931\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 931\u001b[0m     ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n",
      "File \u001b[0;32m/usr/lib/python3.10/selectors.py:416\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n",
      "File \u001b[0;32m~/CMPM118/.venv/lib/python3.10/site-packages/torch/utils/data/_utils/signal_handling.py:73\u001b[0m, in \u001b[0;36m_set_SIGCHLD_handler.<locals>.handler\u001b[0;34m(signum, frame)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mhandler\u001b[39m(signum, frame):\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;66;03m# This following call uses `waitid` with WNOHANG from C side. Therefore,\u001b[39;00m\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;66;03m# Python can still get and update the process status successfully.\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[43m_error_if_any_worker_fails\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m previous_handler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid 81150) is killed by signal: Killed. ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 11\u001b[0m\n\u001b[1;32m      7\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(cached_test, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, num_workers \u001b[38;5;241m=\u001b[39m active_cores, drop_last\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[1;32m      8\u001b[0m                                           collate_fn\u001b[38;5;241m=\u001b[39mtonic\u001b[38;5;241m.\u001b[39mcollation\u001b[38;5;241m.\u001b[39mPadTensors(batch_first\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m---> 11\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch, (data, targets) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28miter\u001b[39m(train_loader)):\n\u001b[1;32m     12\u001b[0m         data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     13\u001b[0m         targets \u001b[38;5;241m=\u001b[39m targets\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/CMPM118/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:734\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    732\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    733\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 734\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    736\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    737\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    738\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    739\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    740\u001b[0m ):\n",
      "File \u001b[0;32m~/CMPM118/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1492\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1489\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data, worker_id)\n\u001b[1;32m   1491\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1492\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1494\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1495\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/CMPM118/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1454\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1450\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1451\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1452\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1453\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1454\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1455\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1456\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/CMPM118/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1298\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1296\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(failed_workers) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1297\u001b[0m     pids_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mstr\u001b[39m(w\u001b[38;5;241m.\u001b[39mpid) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m failed_workers)\n\u001b[0;32m-> 1298\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1299\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataLoader worker (pid(s) \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpids_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) exited unexpectedly\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1300\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m   1301\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, queue\u001b[38;5;241m.\u001b[39mEmpty):\n\u001b[1;32m   1302\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 81150) exited unexpectedly"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Unexpected bus error encountered in worker. This might be caused by insufficient shared memory (shm).\n",
      "\u0000"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "cnt = 0\n",
    "active_cores = 4\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(cached_train, batch_size=64, shuffle=True, num_workers = active_cores, drop_last=True, \n",
    "                                           collate_fn=tonic.collation.PadTensors(batch_first=False))\n",
    "test_loader = torch.utils.data.DataLoader(cached_test, batch_size=32, shuffle=True, num_workers = active_cores, drop_last=True, \n",
    "                                          collate_fn=tonic.collation.PadTensors(batch_first=False))\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch, (data, targets) in enumerate(iter(train_loader)):\n",
    "        data = data.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        net.train()\n",
    "        # propagating one batch through the network and evaluating loss\n",
    "        spk_rec = forward_pass(net, data)\n",
    "        loss = loss_fn(spk_rec, targets)\n",
    "\n",
    "        # Gradient calculation + weight update\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Store loss history for future plotting\n",
    "        loss_hist.append(loss.item())\n",
    "\n",
    "        acc = SF.accuracy_rate(spk_rec, targets)\n",
    "        acc_hist.append(acc)\n",
    "\n",
    "        if cnt % 15 == 0:\n",
    "            print(f\"Epoch {epoch}, Iteration {batch} \\nTrain Loss: {loss.item():.2f}\")\n",
    "            print(f\"Train Accuracy: {acc * 100:.2f}%\")\n",
    "            test_acc = validate_model()            \n",
    "            test_acc_hist.append(test_acc)\n",
    "            print(f\"Test Accuracy: {test_acc * 100:.2f}%\\n\")\n",
    "\n",
    "        cnt+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65373a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this file basically takes the trained model from the call above, the acc_hist, test_acc_hist, and loss_hist, and puts it in a graph. \n",
    "# This file also saves BOTH the model and the graph along with the TRIAL NUMBER. This number is automatically updated. \n",
    "\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18,4))\n",
    "\n",
    "# Plot Train Accuracy\n",
    "axes[0].plot(acc_hist)\n",
    "axes[0].set_title(\"Train Set Accuracy\")\n",
    "axes[0].set_xlabel(\"Iteration\")\n",
    "axes[0].set_ylabel(\"Accuracy\")\n",
    "\n",
    "# Plot Test Accuracy\n",
    "axes[1].plot(test_acc_hist)\n",
    "axes[1].set_title(\"Test Set Accuracy\")\n",
    "axes[1].set_xlabel(\"Iteration\")\n",
    "axes[1].set_ylabel(\"Accuracy\")\n",
    "\n",
    "# Plot Training Loss\n",
    "axes[2].plot(loss_hist)\n",
    "axes[2].set_title(\"Loss History\")\n",
    "axes[2].set_xlabel(\"Iteration\")\n",
    "axes[2].set_ylabel(\"Loss\")\n",
    "\n",
    "\n",
    "# The part below automatically saves the model/accuracy graph in a unique file without you having to do anything\n",
    "\n",
    "experiment_counter_file_path = \"results/large/experiment_counter.txt\"\n",
    "with open(experiment_counter_file_path, \"r\") as f:\n",
    "        num_str = f.read().strip()\n",
    "        num = int(num_str)\n",
    "\n",
    "num += 1\n",
    "\n",
    "with open(experiment_counter_file_path, \"w\") as f:\n",
    "    f.write(str(num))\n",
    "\n",
    "model_save_path = f\"results/large/models/Large_Take{num}.pth\"\n",
    "graph_save_path = f\"results/large/graphs/Large_Take{num}.png\"\n",
    "\n",
    "torch.save(net.state_dict(), model_save_path) \n",
    "plt.savefig(graph_save_path)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
