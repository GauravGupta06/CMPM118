{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<!-- <a href=\"https://colab.research.google.com/github/GauravGupta06/CMPM118/blob/feature%2Ftraining_setup/small_snn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a> -->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0CkxNS9ax0Gx",
        "outputId": "130740f3-822b-45c5-ce92-a96913da55b9"
      },
      "outputs": [],
      "source": [
        "# --- 1. INSTALL LIBRARIES ---\n",
        "%pip install numpy --quiet\n",
        "%pip install tonic --quiet\n",
        "%pip install matplotlib --quiet\n",
        "%pip install snntorch --quiet\n",
        "%pip install torch --quiet\n",
        "%pip install Lempel-Ziv-Complexity --quiet\n",
        "\n",
        "# --- 2. IMPORTS ---\n",
        "import numpy as np\n",
        "import numpy.lib.recfunctions as rf\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import snntorch as snn\n",
        "from snntorch import surrogate, functional as SF, utils\n",
        "import tonic\n",
        "import tonic.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from lempel_ziv_complexity import lempel_ziv_complexity\n",
        "\n",
        "# Check device\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(f\"Using device: {device}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqRHYZAMncoN",
        "outputId": "7c62fa42-d015-4c1c-d774-e1ccb11ada8f"
      },
      "outputs": [],
      "source": [
        "# --- 3. HYPERPARAMETERS ---\n",
        "BIN_SIZE = 15000\n",
        "DOWNSAMPLE = 4\n",
        "TIME_STEPS = 8\n",
        "BATCH_SIZE = 32\n",
        "NUM_CLASSES = 11\n",
        "W, H = 32, 32  # downsampled spatial size\n",
        "grad = surrogate.fast_sigmoid(slope=25)\n",
        "beta = 0.5\n",
        "\n",
        "# --- 4. DATASET TRANSFORMS ---\n",
        "snn_transform = transforms.Compose([\n",
        "    transforms.Denoise(filter_time=10000),\n",
        "    transforms.Downsample(sensor_size=tonic.datasets.DVSGesture.sensor_size,\n",
        "                          target_size=(H, W)),\n",
        "    transforms.ToFrame(sensor_size=(H, W, 2), n_time_bins=TIME_STEPS),\n",
        "    lambda x: torch.from_numpy(x.copy()).permute(0, 3, 1, 2).float()\n",
        "])\n",
        "\n",
        "# --- 5. LOAD FULL DATASET ---\n",
        "full_dataset = tonic.datasets.DVSGesture(save_to=\"./data\", transform=None)\n",
        "dataset_size = len(full_dataset)\n",
        "print(f\"Full dataset size: {dataset_size}\")\n",
        "\n",
        "# --- 6. SPLIT TRAIN/TEST ---\n",
        "TEST_SPLIT_RATIO = 0.2\n",
        "train_size = int(dataset_size * (1 - TEST_SPLIT_RATIO))\n",
        "test_size = dataset_size - train_size\n",
        "torch.manual_seed(42)\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(full_dataset, [train_size, test_size])\n",
        "\n",
        "print(f\"Train: {train_size}, Test: {test_size}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tzDM2wq23WZw"
      },
      "outputs": [],
      "source": [
        "# --- 7. PRE-TRANSFORM DATASET TO SPEED UP ---\n",
        "# print(\"Pre-transforming train dataset...\")\n",
        "# train_dataset_cached = [(snn_transform(events), target) for events, target in train_dataset]\n",
        "# print(\"Pre-transforming test dataset...\")\n",
        "# test_dataset_cached = [(snn_transform(events), target) for events, target in test_dataset]\n",
        "\n",
        "# --- 8. FAST COLLATE FUNCTION ---\n",
        "# def fast_collate(batch):\n",
        "#     data = torch.stack([item[0] for item in batch]).permute(1,0,2,3,4).to(device)\n",
        "#     targets = torch.tensor([item[1] for item in batch], dtype=torch.long).to(device)\n",
        "#     return data, targets\n",
        "\n",
        "def fast_collate_lazy(batch):\n",
        "    # Apply snn_transform only on-the-fly for this batch\n",
        "    data_tensors = [snn_transform(events) for events, target in batch]\n",
        "    # Stack and permute to (T, B, C, H, W)\n",
        "    data = torch.stack(data_tensors).permute(1,0,2,3,4).to(device)\n",
        "    targets = torch.tensor([target for events, target in batch], dtype=torch.long).to(device)\n",
        "    return data, targets\n",
        "\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
        "                          drop_last=True, collate_fn=fast_collate_lazy,\n",
        "                          num_workers=0)  # <--- CHANGE HERE\n",
        "\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
        "                         drop_last=True, collate_fn=fast_collate_lazy,\n",
        "                         num_workers=0)  # <--- CHANGE HERE\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-wsMH4TnlxA",
        "outputId": "65af5d6d-4ba6-46b6-b260-d4bffde32af3"
      },
      "outputs": [],
      "source": [
        "# --- 10. SMALL SNN MODEL ---\n",
        "FLATTEN_SIZE = 8 * (H//2) * (W//2)  # after 1 conv + maxpool\n",
        "class Small_SNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # --- CHANGES: smaller network ---\n",
        "        self.conv = nn.Conv2d(2, 8, 3, padding=1)   # 2->8 filters\n",
        "        self.pool = nn.MaxPool2d(2)\n",
        "        self.lif1 = snn.Leaky(beta=beta, spike_grad=grad, init_hidden=True)\n",
        "        self.fc = nn.Linear(FLATTEN_SIZE, NUM_CLASSES)\n",
        "        self.lif2 = snn.Leaky(beta=beta, spike_grad=grad, init_hidden=True, output=True)\n",
        "\n",
        "    def forward(self, data):\n",
        "        spk_rec = []\n",
        "        utils.reset(self)\n",
        "        for step in range(data.size(0)):  # iterate over time\n",
        "            x = self.conv(data[step])\n",
        "            x = self.pool(x)\n",
        "            spk1 = self.lif1(x) if isinstance(self.lif1, nn.Module) else self.lif1(x)[0]\n",
        "            x = spk1.flatten(1)\n",
        "            x = self.fc(x)\n",
        "            spk2 = self.lif2(x) if isinstance(self.lif2, nn.Module) else self.lif2(x)[0]\n",
        "            spk_rec.append(spk2)\n",
        "        return torch.stack(spk_rec)\n",
        "\n",
        "small_snn_net = Small_SNN().to(device)\n",
        "print(small_snn_net)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ludbR73Pn0t1"
      },
      "outputs": [],
      "source": [
        "# --- 11. TRAINING SETUP ---\n",
        "optimizer = torch.optim.Adam(small_snn_net.parameters(), lr=0.002, betas=(0.9, 0.999))\n",
        "loss_fn = SF.mse_count_loss(correct_rate=0.8, incorrect_rate=0.2)\n",
        "num_epochs = 10  # you can increase later\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SCR-_qwlivcZ"
      },
      "outputs": [],
      "source": [
        "# --- 12. VALIDATION ---\n",
        "def validate_model(loader, net):\n",
        "    net.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for data, targets in loader:\n",
        "            spk_rec = net(data)\n",
        "            correct += SF.accuracy_rate(spk_rec, targets) * data.shape[1]\n",
        "            total += data.shape[1]\n",
        "    net.train()\n",
        "    return correct / total\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "Rz3IXBBni6YD",
        "outputId": "4536667c-7331-49c8-e685-bcc1ca64d721"
      },
      "outputs": [],
      "source": [
        "# --- 13. TRAINING LOOP ---\n",
        "loss_hist = []\n",
        "test_acc_hist = []\n",
        "cnt = 0\n",
        "\n",
        "print(\"Starting training...\")\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for batch_idx, (data, targets) in enumerate(train_loader):\n",
        "        small_snn_net.train()\n",
        "        spk_rec = small_snn_net(data)\n",
        "        loss = loss_fn(spk_rec, targets)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        loss_hist.append(loss.item())\n",
        "\n",
        "        if cnt % 20 == 0:\n",
        "            train_acc = SF.accuracy_rate(spk_rec, targets)\n",
        "            test_acc = validate_model(test_loader, small_snn_net)\n",
        "            test_acc_hist.append(test_acc)\n",
        "            print(f\"Epoch {epoch}, Batch {batch_idx}: Loss={loss.item():.2f}, \"\n",
        "                  f\"Train Acc={train_acc*100:.2f}%, Test Acc={test_acc*100:.2f}%\")\n",
        "        cnt += 1\n",
        "\n",
        "print(\"Training complete!\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyP4gXnbNM62zW0AG1W4bstg",
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
