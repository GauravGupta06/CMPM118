apiVersion: apps/v1
kind: Deployment
metadata:
  name: laurena-dep
  labels:
    app: any-gpu
spec:
  replicas: 1
  revisionHistoryLimit: 2
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 0
      maxSurge: 1
  selector:
    matchLabels:
      app: any-gpu
  template:
    metadata:
      labels:
        app: any-gpu
    spec:
      # For Deployments, restartPolicy is implicitly Always (donâ€™t set it)
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: nvidia.com/gpu.product
                operator: In
                values:
                - NVIDIA-L4
                - NVIDIA-A10
                - NVIDIA-GeForce-RTX-3090
      containers:
      - name: mypod
        image: prattk/remidi:v2.0.3
        resources:
          limits:
            memory: 32Gi
            cpu: "6"
            nvidia.com/gpu: "1"
          requests:
            memory: 32Gi
            cpu: "6"
            nvidia.com/gpu: "1"
        volumeMounts:
        - mountPath: /dev/shm
          name: dshm
        - mountPath: /pvcvolume
          name: examplevol
        command: ["/bin/bash"]
        args:
          - "-c"
          - |
            apt-get update && apt install -y byobu htop git
            eval "$(/root/anaconda3/bin/conda shell.bash hook)" && conda activate pytorch3d_copy
            echo "Waiting for termination signal..."
            while [ ! -f over.txt ]; do sleep 10; done
            echo "Termination signal received. Exiting."
      volumes:
      - name: dshm
        emptyDir:
          medium: Memory
          sizeLimit: 48Gi
      - name: examplevol
        persistentVolumeClaim:
          claimName: pvc
