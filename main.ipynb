{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "102900a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# all required libraries below\n",
    "%pip install numpy --quiet\n",
    "%pip install tonic --quiet\n",
    "%pip install matplotlib --quiet\n",
    "%pip install snntorch --quiet\n",
    "%pip install torch --quiet\n",
    "%pip install Lempel-Ziv-Complexity --quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d6c7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All imports go here\n",
    "import numpy as np\n",
    "import numpy.lib.recfunctions as rf\n",
    "import tonic\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import HTML\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import snntorch as snn\n",
    "from snntorch import surrogate\n",
    "from snntorch import functional as SF\n",
    "from snntorch import utils\n",
    "from lempel_ziv_complexity import lempel_ziv_complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de5a01da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the datasets. This dataset is huge (~17gb), so no need to do this more than once. \n",
    "# If you are opening this on a google colab, there should be a data pipeline between the colab and a google drive location with the data, so no need to install data locally. \n",
    "# tonic.datasets.DVSGesture(save_to=\"/home/gauravgupta/CMPM118/data\", train=True)\n",
    "# tonic.datasets.DVSGesture(save_to=\"/home/gauravgupta/CMPM118/data\", train=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9fa5eca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A single event: (55, 103, False, 13) as (x-pos, y-pos, polarity, timestamp).\n"
     ]
    }
   ],
   "source": [
    "# each sequence of gestures for each subject is divided into 11 .npy files, which are named according to the target labels. \n",
    "# file_name = '/kaggle/input/create-dvs128gesture-tonic-dataset/DVSGesture/ibmGestureTest/user26_led/9.npy'\n",
    "file_name = '/home/gauravgupta/CMPM118/data/DVSGesture/ibmGestureTest/user26_led/9.npy'\n",
    "\n",
    "# each file contains a list of events (x-pos, y-pos, polarity, timestamp).\n",
    "arr = np.load(file_name)\n",
    "arr[:, 3] *= 1000  # convert from ms to us\n",
    "dtype = np.dtype([(\"x\", np.int16), (\"y\", np.int16), (\"p\", bool), (\"t\", np.int64)])\n",
    "arr = rf.unstructured_to_structured(arr, dtype)\n",
    "\n",
    "print(\"A single event:\", arr[0], \"as (x-pos, y-pos, polarity, timestamp).\")\n",
    "\n",
    "# np.savetxt(\"./DVSGesture/ibmGestureTest/user26_led/9.csv\", arr, delimiter=\",\") # save as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c5c8d848",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tonic\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import HTML\n",
    "\n",
    "def to_frames(events):\n",
    "     # creates dense frames from events by binning them in different ways\n",
    "    frame_transform = tonic.transforms.ToFrame(\n",
    "        sensor_size=tonic.datasets.DVSGesture.sensor_size, \n",
    "        #time_window=10000)\n",
    "        n_time_bins=100)\n",
    "        #event_count=1000)\n",
    "    return frame_transform(events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219f46eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LZ complexity for label 1: 7435\n"
     ]
    }
   ],
   "source": [
    "# Calculate lempel ziv complexity for a single piece of data\n",
    "# \n",
    "#  Load in the data. When we do train[1], we are getting one \"video\" of data. \n",
    "dataset_path = '/home/gauravgupta/CMPM118/data'\n",
    "train = tonic.datasets.DVSGesture(save_to=dataset_path, train=True)\n",
    "test = tonic.datasets.DVSGesture(save_to=dataset_path, train=False)\n",
    "events, label = train[8]\n",
    " \n",
    "\n",
    "# Flatten temporal frames into binary spike stream\n",
    "spike_seq = (events['p'] > 0).astype(int).flatten()  # 1 if spike, 0 if inactive\n",
    "spike_seq_string = ''.join(map(str, spike_seq.tolist()))\n",
    "lz_score = lempel_ziv_complexity(spike_seq_string)\n",
    "print(f\"LZ complexity for label {label}: {lz_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f8b3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '/home/gauravgupta/CMPM118/data'\n",
    "train = tonic.datasets.DVSGesture(save_to=dataset_path, train=True)\n",
    "test = tonic.datasets.DVSGesture(save_to=dataset_path, train=False)\n",
    "\n",
    "events, label = train[6]\n",
    "frames = to_frames(events)\n",
    "\n",
    "print(\"Train dataset contains\", len(train), \"samples.\")\n",
    "print(\"There are\", len(events), \"events in the selected sample.\")\n",
    "print(\"A single event:\", events[1], \"as (x-pos, y-pos, polarity, timestamp).\")\n",
    "print (frames.shape, label)\n",
    "\n",
    "ani = tonic.utils.plot_animation(frames) # plot one frame\n",
    "HTML(ani.to_jshtml()) # animate all frames\n",
    "\n",
    "lzc = \"\"\n",
    "lzc_list = []\n",
    "\n",
    "binary_frames = (frames > 0).astype(int)\n",
    "flat_frames = binary_frames.reshape(binary_frames.shape[0], -1)\n",
    "for frame in flat_frames:\n",
    "    lzc = \"\".join(map(str, frame))\n",
    "    lzc_list.append(lempel_ziv_complexity(lzc))\n",
    "\n",
    "fig, axes = plt.subplots(1, 1, figsize=(18,4))\n",
    "axes.plot(lzc_list)\n",
    "axes.set_title(\"LZC Over Time\")\n",
    "axes.set_xlabel(\"Frame\")\n",
    "axes.set_ylabel(\"LZC\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ded11e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "w,h=32,32\n",
    "n_frames=32 #100\n",
    "debug = False\n",
    "\n",
    "transforms = tonic.transforms.Compose([\n",
    "    tonic.transforms.Denoise(filter_time=10000), # removes outlier events with inactive surrounding pixels for 10ms\n",
    "    tonic.transforms.Downsample(sensor_size=tonic.datasets.DVSGesture.sensor_size, target_size=(w,h)), # downsampling image\n",
    "    tonic.transforms.ToFrame(sensor_size=(w,h,2), n_time_bins=n_frames), # n_frames frames per trail\n",
    "])\n",
    "\n",
    "train2 = tonic.datasets.DVSGesture(save_to=dataset_path, transform=transforms, train=True)\n",
    "test2 = tonic.datasets.DVSGesture(save_to=dataset_path, transform=transforms, train=False)\n",
    "\n",
    "cached_train = train2 if debug else tonic.DiskCachedDataset(train2, cache_path='/home/gauravgupta/CMPM118/data/dvsgesture/train')\n",
    "cached_test = test2 if debug else tonic.DiskCachedDataset(test2, cache_path='/home/gauravgupta/CMPM118/data/dvsgesture/test')\n",
    "\n",
    "frames, label = cached_train[1]\n",
    "ani = tonic.utils.plot_animation(frames)\n",
    "print(frames.shape, label)\n",
    "HTML(ani.to_jshtml())\n",
    "\n",
    "lzc = \"\"\n",
    "lzc_list = []\n",
    "\n",
    "binary_frames = (frames > 0).astype(int)\n",
    "flat_frames = binary_frames.reshape(binary_frames.shape[0], -1)\n",
    "for frame in flat_frames:\n",
    "    lzc = \"\".join(map(str, frame))\n",
    "    lzc_list.append(lempel_ziv_complexity(lzc))\n",
    "\n",
    "fig, axes = plt.subplots(1, 1, figsize=(18,4))\n",
    "axes.plot(lzc_list)\n",
    "axes.set_title(\"LZC Over Time\")\n",
    "axes.set_xlabel(\"Frame\")\n",
    "axes.set_ylabel(\"LZC\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0c20aff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "31635f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad = snn.surrogate.fast_sigmoid(slope=25) # surrogate.atan()\n",
    "beta = 0.5\n",
    "\n",
    "# 12C5-MP2-32C5-MP2-800FC11 https://snntorch.readthedocs.io/en/latest/tutorials/tutorial_7.html\n",
    "net = nn.Sequential(\n",
    "    nn.Conv2d(2, 12, 5), # in_channels, out_channels, kernel_size\n",
    "    nn.MaxPool2d(2),\n",
    "    snn.Leaky(beta=beta, spike_grad=grad, init_hidden=True),\n",
    "    nn.Conv2d(12, 32, 5),\n",
    "    nn.MaxPool2d(2),\n",
    "    snn.Leaky(beta=beta, spike_grad=grad, init_hidden=True),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(800, 11), #800\n",
    "    snn.Leaky(beta=beta, spike_grad=grad, init_hidden=True, output=True)\n",
    ").to(device)\n",
    "\n",
    "def forward_pass(net, data):\n",
    "    spk_rec = []\n",
    "    snn.utils.reset(net)  # resets hidden states for all LIF neurons in net\n",
    "    for step in range(data.size(0)): # data.size(0) = number of time steps\n",
    "        spk_out, mem_out = net(data[step])\n",
    "        spk_rec.append(spk_out)\n",
    "    return torch.stack(spk_rec)\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.002, betas=(0.9, 0.999))\n",
    "loss_fn = SF.mse_count_loss(correct_rate=0.8, incorrect_rate=0.2)\n",
    "\n",
    "loss_hist = []\n",
    "acc_hist = []\n",
    "test_acc_hist = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "af65fd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model():\n",
    "    correct, total = 0, 0  \n",
    "    for batch, (data, targets) in enumerate(iter(test_loader)): \n",
    "        data, targets = data.to(device), targets.to(device) # [n_frames, batch, polarity, x-pos, y-pos] [batch] \n",
    "        spk_rec = forward_pass(net, data)         \n",
    "        correct += SF.accuracy_rate(spk_rec, targets) * data.shape[0]\n",
    "        total += data.shape[0]\n",
    "    return correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851d016a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "cnt = 0\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(cached_train, batch_size=64, shuffle=True, drop_last=True, \n",
    "                                           collate_fn=tonic.collation.PadTensors(batch_first=False))\n",
    "test_loader = torch.utils.data.DataLoader(cached_test, batch_size=32, shuffle=True, drop_last=True, \n",
    "                                          collate_fn=tonic.collation.PadTensors(batch_first=False))\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch, (data, targets) in enumerate(iter(train_loader)):\n",
    "        data = data.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        net.train()\n",
    "        # propagating one batch through the network and evaluating loss\n",
    "        spk_rec = forward_pass(net, data)\n",
    "        loss = loss_fn(spk_rec, targets)\n",
    "\n",
    "        # Gradient calculation + weight update\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Store loss history for future plotting\n",
    "        loss_hist.append(loss.item())\n",
    "\n",
    "        acc = SF.accuracy_rate(spk_rec, targets)\n",
    "        acc_hist.append(acc)\n",
    "\n",
    "        if cnt % 50 == 0:\n",
    "            print(f\"Epoch {epoch}, Iteration {batch} \\nTrain Loss: {loss.item():.2f}\")\n",
    "            print(f\"Train Accuracy: {acc * 100:.2f}%\")\n",
    "            test_acc = validate_model()            \n",
    "            test_acc_hist.append(test_acc)\n",
    "            print(f\"Test Accuracy: {test_acc * 100:.2f}%\\n\")\n",
    "\n",
    "        cnt+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
