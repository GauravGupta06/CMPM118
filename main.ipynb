{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "102900a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# all required libraries below\n",
    "%pip install numpy --quiet\n",
    "%pip install tonic --quiet\n",
    "%pip install matplotlib --quiet\n",
    "%pip install snntorch --quiet\n",
    "%pip install torch --quiet\n",
    "%pip install Lempel-Ziv-Complexity --quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d6c7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All imports go here\n",
    "import numpy as np\n",
    "import numpy.lib.recfunctions as rf\n",
    "import tonic\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import HTML\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import snntorch as snn\n",
    "from snntorch import surrogate\n",
    "from snntorch import functional as SF\n",
    "from snntorch import utils\n",
    "from lempel_ziv_complexity import lempel_ziv_complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de5a01da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the datasets. This dataset is huge (~17gb), so no need to do this more than once. \n",
    "# If you are opening this on a google colab, there should be a data pipeline between the colab and a google drive location with the data, so no need to install data locally. \n",
    "# tonic.datasets.DVSGesture(save_to=\"/home/gauravgupta/CMPM118/data\", train=True)\n",
    "# tonic.datasets.DVSGesture(save_to=\"/home/gauravgupta/CMPM118/data\", train=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9fa5eca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A single event: (55, 103, False, 13) as (x-pos, y-pos, polarity, timestamp).\n"
     ]
    }
   ],
   "source": [
    "# each sequence of gestures for each subject is divided into 11 .npy files, which are named according to the target labels. \n",
    "# file_name = '/kaggle/input/create-dvs128gesture-tonic-dataset/DVSGesture/ibmGestureTest/user26_led/9.npy'\n",
    "file_name = '/home/gauravgupta/CMPM118/data/DVSGesture/ibmGestureTest/user26_led/9.npy'\n",
    "\n",
    "# each file contains a list of events (x-pos, y-pos, polarity, timestamp).\n",
    "arr = np.load(file_name)\n",
    "arr[:, 3] *= 1000  # convert from ms to us\n",
    "dtype = np.dtype([(\"x\", np.int16), (\"y\", np.int16), (\"p\", bool), (\"t\", np.int64)])\n",
    "arr = rf.unstructured_to_structured(arr, dtype)\n",
    "\n",
    "print(\"A single event:\", arr[0], \"as (x-pos, y-pos, polarity, timestamp).\")\n",
    "\n",
    "# np.savetxt(\"./DVSGesture/ibmGestureTest/user26_led/9.csv\", arr, delimiter=\",\") # save as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c5c8d848",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tonic\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import HTML\n",
    "\n",
    "def to_frames(events):\n",
    "     # creates dense frames from events by binning them in different ways\n",
    "    frame_transform = tonic.transforms.ToFrame(\n",
    "        sensor_size=tonic.datasets.DVSGesture.sensor_size, \n",
    "        #time_window=10000)\n",
    "        n_time_bins=100)\n",
    "        #event_count=1000)\n",
    "    return frame_transform(events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219f46eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LZ complexity for label 1: 7435\n"
     ]
    }
   ],
   "source": [
    "# Calculate lempel ziv complexity for a single piece of data\n",
    "# \n",
    "#  Load in the data. When we do train[1], we are getting one \"video\" of data. \n",
    "dataset_path = '/home/gauravgupta/CMPM118/data'\n",
    "train = tonic.datasets.DVSGesture(save_to=dataset_path, train=True)\n",
    "test = tonic.datasets.DVSGesture(save_to=dataset_path, train=False)\n",
    "events, label = train[8]\n",
    " \n",
    "\n",
    "# Flatten temporal frames into binary spike stream\n",
    "spike_seq = (events['p'] > 0).astype(int).flatten()  # 1 if spike, 0 if inactive\n",
    "spike_seq_string = ''.join(map(str, spike_seq.tolist()))\n",
    "lz_score = lempel_ziv_complexity(spike_seq_string)\n",
    "print(f\"LZ complexity for label {label}: {lz_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f8b3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '/home/gauravgupta/CMPM118/data'\n",
    "train = tonic.datasets.DVSGesture(save_to=dataset_path, train=True)\n",
    "test = tonic.datasets.DVSGesture(save_to=dataset_path, train=False)\n",
    "\n",
    "events, label = train[6]\n",
    "frames = to_frames(events)\n",
    "\n",
    "print(\"Train dataset contains\", len(train), \"samples.\")\n",
    "print(\"There are\", len(events), \"events in the selected sample.\")\n",
    "print(\"A single event:\", events[1], \"as (x-pos, y-pos, polarity, timestamp).\")\n",
    "print (frames.shape, label)\n",
    "\n",
    "ani = tonic.utils.plot_animation(frames) # plot one frame\n",
    "HTML(ani.to_jshtml()) # animate all frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ded11e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "w,h=32,32\n",
    "n_frames=32 #100\n",
    "debug = False\n",
    "\n",
    "transforms = tonic.transforms.Compose([\n",
    "    tonic.transforms.Denoise(filter_time=10000), # removes outlier events with inactive surrounding pixels for 10ms\n",
    "    tonic.transforms.Downsample(sensor_size=tonic.datasets.DVSGesture.sensor_size, target_size=(w,h)), # downsampling image\n",
    "    tonic.transforms.ToFrame(sensor_size=(w,h,2), n_time_bins=n_frames), # n_frames frames per trail\n",
    "])\n",
    "\n",
    "train2 = tonic.datasets.DVSGesture(save_to=dataset_path, transform=transforms, train=True)\n",
    "test2 = tonic.datasets.DVSGesture(save_to=dataset_path, transform=transforms, train=False)\n",
    "\n",
    "cached_train = train2 if debug else tonic.DiskCachedDataset(train2, cache_path='/home/gauravgupta/CMPM118/data/dvsgesture/train')\n",
    "cached_test = test2 if debug else tonic.DiskCachedDataset(test2, cache_path='/home/gauravgupta/CMPM118/data/dvsgesture/test')\n",
    "\n",
    "frames, label = cached_train[1]\n",
    "ani = tonic.utils.plot_animation(frames)\n",
    "print(frames.shape, label)\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0c20aff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "31635f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad = snn.surrogate.fast_sigmoid(slope=25) # surrogate.atan()\n",
    "beta = 0.5\n",
    "\n",
    "# 12C5-MP2-32C5-MP2-800FC11 https://snntorch.readthedocs.io/en/latest/tutorials/tutorial_7.html\n",
    "net = nn.Sequential(\n",
    "    nn.Conv2d(2, 12, 5), # in_channels, out_channels, kernel_size\n",
    "    nn.MaxPool2d(2),\n",
    "    snn.Leaky(beta=beta, spike_grad=grad, init_hidden=True),\n",
    "    nn.Conv2d(12, 32, 5),\n",
    "    nn.MaxPool2d(2),\n",
    "    snn.Leaky(beta=beta, spike_grad=grad, init_hidden=True),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(800, 11), #800\n",
    "    snn.Leaky(beta=beta, spike_grad=grad, init_hidden=True, output=True)\n",
    ").to(device)\n",
    "\n",
    "def forward_pass(net, data):\n",
    "    spk_rec = []\n",
    "    snn.utils.reset(net)  # resets hidden states for all LIF neurons in net\n",
    "    for step in range(data.size(0)): # data.size(0) = number of time steps\n",
    "        spk_out, mem_out = net(data[step])\n",
    "        spk_rec.append(spk_out)\n",
    "    return torch.stack(spk_rec)\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.002, betas=(0.9, 0.999))\n",
    "loss_fn = SF.mse_count_loss(correct_rate=0.8, incorrect_rate=0.2)\n",
    "\n",
    "loss_hist = []\n",
    "acc_hist = []\n",
    "test_acc_hist = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "af65fd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model():\n",
    "    correct, total = 0, 0  \n",
    "    for batch, (data, targets) in enumerate(iter(test_loader)): \n",
    "        data, targets = data.to(device), targets.to(device) # [n_frames, batch, polarity, x-pos, y-pos] [batch] \n",
    "        spk_rec = forward_pass(net, data)         \n",
    "        correct += SF.accuracy_rate(spk_rec, targets) * data.shape[0]\n",
    "        total += data.shape[0]\n",
    "    return correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "569f3711",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/CMPM118/.venv/lib/python3.10/site-packages/tonic/cached_dataset.py:145\u001b[0m, in \u001b[0;36mDiskCachedDataset.__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 145\u001b[0m     data, targets \u001b[38;5;241m=\u001b[39m \u001b[43mload_from_disk_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mFileNotFoundError\u001b[39;00m, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m _:\n",
      "File \u001b[0;32m~/CMPM118/.venv/lib/python3.10/site-packages/tonic/cached_dataset.py:220\u001b[0m, in \u001b[0;36mload_from_disk_cache\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m    219\u001b[0m target_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 220\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mh5py\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name, _list \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m\"\u001b[39m], [data_list, target_list]):\n",
      "File \u001b[0;32m~/CMPM118/.venv/lib/python3.10/site-packages/h5py/_hl/files.py:564\u001b[0m, in \u001b[0;36mFile.__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[1;32m    561\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[1;32m    562\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[1;32m    563\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[0;32m--> 564\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mmake_fid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserblock_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfcpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mswmr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mswmr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n",
      "File \u001b[0;32m~/CMPM118/.venv/lib/python3.10/site-packages/h5py/_hl/files.py:238\u001b[0m, in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    237\u001b[0m         flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mACC_SWMR_READ\n\u001b[0;32m--> 238\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mh5f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32mh5py/_objects.pyx:56\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:57\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5f.pyx:102\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to synchronously open file (unable to open file: name = '/home/gauravgupta/CMPM118/data/dvsgesture/train/975_0.hdf5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 10\u001b[0m\n\u001b[1;32m      6\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(cached_test, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, drop_last\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[1;32m      7\u001b[0m                                           collate_fn\u001b[38;5;241m=\u001b[39mtonic\u001b[38;5;241m.\u001b[39mcollation\u001b[38;5;241m.\u001b[39mPadTensors(batch_first\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m---> 10\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch, (data, targets) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28miter\u001b[39m(train_loader)):\n\u001b[1;32m     11\u001b[0m         data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     12\u001b[0m         targets \u001b[38;5;241m=\u001b[39m targets\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/CMPM118/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:734\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    732\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    733\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 734\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    736\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    737\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    738\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    739\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    740\u001b[0m ):\n",
      "File \u001b[0;32m~/CMPM118/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:790\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    789\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 790\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    791\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    792\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/CMPM118/.venv/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/CMPM118/.venv/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/CMPM118/.venv/lib/python3.10/site-packages/tonic/cached_dataset.py:152\u001b[0m, in \u001b[0;36mDiskCachedDataset.__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mFileNotFoundError\u001b[39;00m, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m _:\n\u001b[1;32m    147\u001b[0m     logging\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m    148\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in cache, generating it now\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    149\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    150\u001b[0m     )\n\u001b[0;32m--> 152\u001b[0m     data, targets \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    153\u001b[0m     save_to_disk_cache(\n\u001b[1;32m    154\u001b[0m         data, targets, file_path\u001b[38;5;241m=\u001b[39mfile_path, compress\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompress\n\u001b[1;32m    155\u001b[0m     )\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;66;03m# format might change during save to hdf5, i.e. tensors -> np arrays\u001b[39;00m\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;66;03m# We load the sample here again to keep the output format consistent.\u001b[39;00m\n",
      "File \u001b[0;32m~/CMPM118/.venv/lib/python3.10/site-packages/tonic/datasets/dvsgesture.py:115\u001b[0m, in \u001b[0;36mDVSGesture.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    113\u001b[0m target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtargets[index]\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 115\u001b[0m     events \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevents\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    117\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[0;32m~/CMPM118/.venv/lib/python3.10/site-packages/tonic/transforms.py:32\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, events)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(events) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     31\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m     events \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevents\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m events\n",
      "File \u001b[0;32m~/CMPM118/.venv/lib/python3.10/site-packages/tonic/transforms.py:119\u001b[0m, in \u001b[0;36mDenoise.__call__\u001b[0;34m(self, events)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, events):\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdenoise_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilter_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilter_time\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/CMPM118/.venv/lib/python3.10/site-packages/tonic/functional/denoise.py:36\u001b[0m, in \u001b[0;36mdenoise_numpy\u001b[0;34m(events, filter_time)\u001b[0m\n\u001b[1;32m     30\u001b[0m t \u001b[38;5;241m=\u001b[39m event[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     31\u001b[0m timestamp_memory[x, y] \u001b[38;5;241m=\u001b[39m t \u001b[38;5;241m+\u001b[39m filter_time\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m     33\u001b[0m     (x \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m timestamp_memory[x \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, y] \u001b[38;5;241m>\u001b[39m t)\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m (x \u001b[38;5;241m<\u001b[39m width \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m timestamp_memory[x \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, y] \u001b[38;5;241m>\u001b[39m t)\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m (y \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m timestamp_memory[x, y \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m t)\n\u001b[0;32m---> 36\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m (y \u001b[38;5;241m<\u001b[39m height \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m timestamp_memory[x, y \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m t)\n\u001b[1;32m     37\u001b[0m ):\n\u001b[1;32m     38\u001b[0m     events_copy[copy_index] \u001b[38;5;241m=\u001b[39m event\n\u001b[1;32m     39\u001b[0m     copy_index \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "cnt = 0\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(cached_train, batch_size=64, shuffle=True, drop_last=True, \n",
    "                                           collate_fn=tonic.collation.PadTensors(batch_first=False))\n",
    "test_loader = torch.utils.data.DataLoader(cached_test, batch_size=32, shuffle=True, drop_last=True, \n",
    "                                          collate_fn=tonic.collation.PadTensors(batch_first=False))\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch, (data, targets) in enumerate(iter(train_loader)):\n",
    "        data = data.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        net.train()\n",
    "        # propagating one batch through the network and evaluating loss\n",
    "        spk_rec = forward_pass(net, data)\n",
    "        loss = loss_fn(spk_rec, targets)\n",
    "\n",
    "        # Gradient calculation + weight update\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Store loss history for future plotting\n",
    "        loss_hist.append(loss.item())\n",
    "\n",
    "        acc = SF.accuracy_rate(spk_rec, targets)\n",
    "        acc_hist.append(acc)\n",
    "\n",
    "        if cnt % 50 == 0:\n",
    "            print(f\"Epoch {epoch}, Iteration {batch} \\nTrain Loss: {loss.item():.2f}\")\n",
    "            print(f\"Train Accuracy: {acc * 100:.2f}%\")\n",
    "            test_acc = validate_model()            \n",
    "            test_acc_hist.append(test_acc)\n",
    "            print(f\"Test Accuracy: {test_acc * 100:.2f}%\\n\")\n",
    "\n",
    "        cnt+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
